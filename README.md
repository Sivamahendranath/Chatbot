ğŸ“š Smart Document Assistant (Offline Chatbot with PDF & URL Support)
This project is an intelligent, fully offline chatbot application built using Streamlit, LangChain, FAISS, and Ollama, designed to help users chat with documents (PDFs and Web URLs). It uses local LLMs via Ollama, supports voice input, provides document insights and statistics, and presents everything in a clean, user-friendly UI.

ğŸ¯ Purpose
This chatbot allows users to:

Upload PDF documents or enter web URLs.

Ask natural language questions about the content.

Receive answers generated by a local large language model (LLM).

View source excerpts, metadata, and word frequency insights.

Use voice input and export conversations.

ğŸ”§ Key Features
ğŸ“„ Document Processing
PDF Upload: Extracts text and metadata using PyMuPDF.

URL Input: Scrapes web content using trafilatura, newspaper3k, BeautifulSoup, and html2text.

ğŸ” Semantic Search + RAG
Splits text into meaningful chunks using LangChainâ€™s RecursiveCharacterTextSplitter.

Embeds chunks using HuggingFace embeddings.

Stores them in FAISS for efficient vector search.

Uses RetrievalQA chain to generate context-aware answers.

ğŸ¤– Local LLM Integration
Uses Ollama to run local models like mistral, llama2, gemma, etc.

All processing stays offline after setup.

ğŸ¤ Voice Input
Uses SpeechRecognition to allow users to speak questions via microphone.

ğŸ“Š Document Insights
Displays document metadata (title, author, pages, domain, etc.).

Generates word frequency charts.

Computes document statistics (length, paragraph count, average word length, etc.).

ğŸ’¬ Chat UI
Custom Streamlit UI with clean CSS styles.

Chat interface with user and assistant message bubbles.

Maintains chat history in-session.

Option to export the chat as a Markdown file.

ğŸ“ Project Structure
project/
â”œâ”€â”€ app.py                  # Main Streamlit app script
â””â”€â”€ requirements.txt        # Python dependencies

ğŸ› ï¸ Installation Instructions
Install Python packages:
pip install -r requirements.txt
Install and run Ollama:
ollama pull mistral
ollama serve
Run the chatbot:
streamlit run chatbot.txt
ğŸ’¡ Example Use Cases
Chat with academic or policy PDFs.

Analyze and summarize web articles offline.

Voice-interact with long documents.

Research assistant for structured document exploration.

ğŸ“¦ Requirements
Your requirements.txt should include (at minimum):

streamlit
torch
langchain
langchain-community
faiss-cpu
sentence-transformers
PyMuPDF
speechrecognition
html2text
newspaper3k
beautifulsoup4
lxml
matplotlib
pandas
numpy
pydub
trafilatura
requests
ğŸ§  How It Works
Upload a document (PDF or URL)

Text is extracted and split into chunks

Chunks are embedded and indexed via FAISS

A local LLM (via Ollama) answers questions using relevant chunks (RAG)

Answers are shown in the UI with optional source excerpts

Chat history can be exported; metadata and insights are visualized

ğŸ” Offline-First Design
All models run locally via Ollama

Whisper-ready if offline voice transcription is needed

No external API calls are used once installed

ğŸ“¤ Export & Reset
Download full chat history as a Markdown report

Reset assistant state and start over easily from the sidebar

ğŸ“ License
This project is open-source and MIT licensed.

++++++++++++++++++Check the Install.txt file for how to install the OLAMMA Model.
